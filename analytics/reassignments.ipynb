{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50c63b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349c43a4",
   "metadata": {},
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc7c3f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_a1_2_path = \"/home/pbiel/repos/jask/analytics/reassignments/a1_2.csv\"\n",
    "dataset_a1_2 = pd.read_csv(dataset_a1_2_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31e49c9",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bb66311",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_basic_stats(df):\n",
    "    print(f\"\\n=== BASIC STATISTICS ===\")\n",
    "    print(f\"Total reassignments: {len(df):,}\")\n",
    "    print(f\"Unique processes moved: {df['ProcessID'].nunique():,}\")\n",
    "    print(f\"Unique services: {df['Service'].nunique():,}\")\n",
    "    print(f\"Time span: {(df['Timestamp'].max() - df['Timestamp'].min()) / 1000:.2f} seconds\")\n",
    "\n",
    "    # Calculate process sizes (sum of requirements)\n",
    "    def parse_requirements(req_str):\n",
    "        try:\n",
    "            return ast.literal_eval(req_str)\n",
    "        except:\n",
    "            return [0, 0, 0, 0]\n",
    "        \n",
    "    df['Requirements_List'] = df['Requirements'].apply(parse_requirements)\n",
    "    df['ProcessSize'] = df['Requirements_List'].apply(sum)\n",
    "    \n",
    "    print(f\"\\n=== PROCESS SIZE ANALYSIS ===\")\n",
    "    print(f\"Average process size: {df['ProcessSize'].mean():.0f}\")\n",
    "    print(f\"Median process size: {df['ProcessSize'].median():.0f}\")\n",
    "    print(f\"Min process size: {df['ProcessSize'].min():.0f}\")\n",
    "    print(f\"Max process size: {df['ProcessSize'].max():.0f}\")\n",
    "\n",
    "    # Analyze moves per process\n",
    "    moves_per_process = df['ProcessID'].value_counts()\n",
    "    print(f\"\\n=== MOVEMENT FREQUENCY ===\")\n",
    "    print(f\"Processes moved once: {(moves_per_process == 1).sum():,}\")\n",
    "    print(f\"Processes moved multiple times: {(moves_per_process > 1).sum():,}\")\n",
    "    print(f\"Most moved process: Process {moves_per_process.index[0]} with {moves_per_process.iloc[0]} moves\")\n",
    "\n",
    "    # Analyze by process size quartiles\n",
    "    size_quartiles = df['ProcessSize'].quantile([0.25, 0.5, 0.75])\n",
    "    print(f\"\\n=== MOVEMENT BY PROCESS SIZE ===\")\n",
    "    print(f\"25th percentile size: {size_quartiles[0.25]:.0f}\")\n",
    "    print(f\"50th percentile size: {size_quartiles[0.5]:.0f}\")\n",
    "    print(f\"75th percentile size: {size_quartiles[0.75]:.0f}\")\n",
    "\n",
    "    # Categorize processes by size\n",
    "    df['SizeCategory'] = pd.cut(\n",
    "        df['ProcessSize'], \n",
    "        bins = [\n",
    "            0, \n",
    "            size_quartiles[0.25], \n",
    "            size_quartiles[0.5],\n",
    "            size_quartiles[0.75], \n",
    "            float('inf')\n",
    "        ],\n",
    "        labels = [\n",
    "            'Small', \n",
    "            'Medium', \n",
    "            'Large', \n",
    "            'XLarge'\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    size_movement_count = df.groupby('SizeCategory').size()\n",
    "    print(\"\\nMovements by size category:\")\n",
    "    for category, count in size_movement_count.items():\n",
    "        print(f\"  {category}: {count:,} moves ({count/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    # Analyze improvement over time\n",
    "    print(f\"\\n=== IMPROVEMENT ANALYSIS ===\")\n",
    "    print(f\"Initial improvement: {df['Improvement'].iloc[0]:.4f}%\")\n",
    "    print(f\"Final improvement: {df['Improvement'].iloc[-1]:.4f}%\")\n",
    "    print(f\"Total improvement gain: {df['Improvement'].iloc[-1] - df['Improvement'].iloc[0]:.4f}%\")\n",
    "    \n",
    "    # Analyze move cost distribution\n",
    "    print(f\"\\n=== MOVE COST ANALYSIS ===\")\n",
    "    print(f\"Average move cost: {df['MoveCost'].mean():.2f}\")\n",
    "    print(f\"Median move cost: {df['MoveCost'].median():.2f}\")\n",
    "    print(f\"Move cost distribution:\")\n",
    "    move_cost_counts = df['MoveCost'].value_counts().sort_index()\n",
    "    for cost, count in move_cost_counts.head(10).items():\n",
    "        print(f\"  Cost {cost}: {count:,} moves ({count/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    # Analyze temporal patterns\n",
    "    print(f\"\\n=== TEMPORAL PATTERNS ===\")\n",
    "    df['TimeFromStart'] = (df['Timestamp'] - df['Timestamp'].min()) / 1000  # Convert to seconds\n",
    "    \n",
    "    # Divide into time periods\n",
    "    time_periods = pd.cut(df['TimeFromStart'], bins=5, labels=['Period1', 'Period2', 'Period3', 'Period4', 'Period5'])\n",
    "    period_stats = df.groupby(time_periods).agg({\n",
    "        'ProcessSize': 'mean',\n",
    "        'MoveCost': 'mean',\n",
    "        'ProcessID': 'count'\n",
    "    })\n",
    "    \n",
    "    print(\"\\nAverage process size moved per time period:\")\n",
    "    for period, stats in period_stats.iterrows():\n",
    "        print(f\"  {period}: {stats['ProcessSize']:.0f} (avg size), {stats['ProcessID']:,} moves\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a6e586",
   "metadata": {},
   "source": [
    "# Dataset A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcaa8b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== BASIC STATISTICS ===\n",
      "Total reassignments: 169,711\n",
      "Unique processes moved: 881\n",
      "Unique services: 862\n",
      "Time span: 8.62 seconds\n",
      "\n",
      "=== PROCESS SIZE ANALYSIS ===\n",
      "Average process size: 121629\n",
      "Median process size: 57721\n",
      "Min process size: 3244\n",
      "Max process size: 4825692\n",
      "\n",
      "=== MOVEMENT FREQUENCY ===\n",
      "Processes moved once: 5\n",
      "Processes moved multiple times: 876\n",
      "Most moved process: Process 423 with 505 moves\n",
      "\n",
      "=== MOVEMENT BY PROCESS SIZE ===\n",
      "25th percentile size: 24271\n",
      "50th percentile size: 57721\n",
      "75th percentile size: 153593\n",
      "\n",
      "Movements by size category:\n",
      "  Small: 42,571 moves (25.1%)\n",
      "  Medium: 42,638 moves (25.1%)\n",
      "  Large: 42,118 moves (24.8%)\n",
      "  XLarge: 42,384 moves (25.0%)\n",
      "\n",
      "=== IMPROVEMENT ANALYSIS ===\n",
      "Initial improvement: 0.0000%\n",
      "Final improvement: 26.7601%\n",
      "Total improvement gain: 26.7601%\n",
      "\n",
      "=== MOVE COST ANALYSIS ===\n",
      "Average move cost: 1.00\n",
      "Median move cost: 1.00\n",
      "Move cost distribution:\n",
      "  Cost 1: 169,711 moves (100.0%)\n",
      "\n",
      "=== TEMPORAL PATTERNS ===\n",
      "\n",
      "Average process size moved per time period:\n",
      "  Period1: 136486 (avg size), 77,049.0 moves\n",
      "  Period2: 105681 (avg size), 39,564.0 moves\n",
      "  Period3: 98146 (avg size), 19,890.0 moves\n",
      "  Period4: 126717 (avg size), 10,969.0 moves\n",
      "  Period5: 117020 (avg size), 22,239.0 moves\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_216837/266750007.py:56: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  size_movement_count = df.groupby('SizeCategory').size()\n",
      "/tmp/ipykernel_216837/266750007.py:82: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  period_stats = df.groupby(time_periods).agg({\n"
     ]
    }
   ],
   "source": [
    "get_basic_stats(dataset_a1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe4488a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
